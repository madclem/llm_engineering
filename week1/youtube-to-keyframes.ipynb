{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7943d3c-3034-4b99-a428-cf6cffea9dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-transcript-api\n",
      "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->youtube-transcript-api) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
      "Downloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: youtube-transcript-api\n",
      "Successfully installed youtube-transcript-api-0.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bec165d-d7eb-4468-8cc2-70565ba56154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoutubeVideoID:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.video_id = self.extract_video_id(url)\n",
    "\n",
    "    def extract_video_id(self, url):\n",
    "        \"\"\"\n",
    "        Extracts the YouTube video ID from a given URL.\n",
    "        Supports both regular and shortened URLs.\n",
    "        \"\"\"\n",
    "        # Regular expression to match YouTube video URL and extract the video ID\n",
    "        regex = r\"(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|\\S*\\?v=)|(?:youtu\\.be\\/))([a-zA-Z0-9_-]{11})\"\n",
    "        match = re.match(regex, url)\n",
    "        \n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid YouTube URL\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Video ID: {self.video_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822a58c1-9998-444b-9476-174d3ec37bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: kqaMIFEz15s\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "video_url = \"https://www.youtube.com/watch?v=kqaMIFEz15s\"\n",
    "\n",
    "yt_video = YoutubeVideoID(video_url)\n",
    "print(yt_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586a0be8-96a4-4a62-81ca-48435df54624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transcript(video_id, language='en'):\n",
    "    try:\n",
    "        # Try to get the transcript in the desired language (Indonesian by default)\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\n",
    "        # Join all the 'text' fields into a single string\n",
    "        return \" \".join([item['text'] for item in transcript])\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching transcript: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c20d9669-90ab-4428-b8bf-022af7aa7ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_text(text, chunk_size=3000):\n",
    "    \"\"\"\n",
    "    Splits large text into smaller chunks based on the given chunk size.\n",
    "    Ensures that chunks end with a full stop where possible to maintain sentence integrity.\n",
    "    \n",
    "    :param text: str, the text to be split\n",
    "    :param chunk_size: int, maximum size of each chunk (default 3000 characters)\n",
    "    :return: list of str, where each str is a chunk of text\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    while len(text) > chunk_size:\n",
    "        # Find the last full stop within or at the chunk size\n",
    "        split_point = text.rfind('.', 0, chunk_size + 1)  # +1 to include the period itself if it's at chunk_size\n",
    "        if split_point == -1:  # No period found within the chunk size\n",
    "            split_point = chunk_size\n",
    "        \n",
    "        # Append the chunk, ensuring we don't strip spaces that might be part of the sentence structure\n",
    "        chunks.append(text[:split_point + 1] if split_point != chunk_size else text[:chunk_size])\n",
    "        text = text[split_point + 1:] if split_point != chunk_size else text[chunk_size:]\n",
    "    \n",
    "    # Add the remaining text as the final chunk, only strip if there's content\n",
    "    if text:\n",
    "        chunks.append(text.strip())\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f4624c6-0e37-4b6f-90b2-d2cae88d49a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to summarize text using ChatGPT\n",
    "def summarize_text(text):\n",
    "    try:\n",
    "        system_prompts = \"\"\"\n",
    "        You're a very concise assistant that go through Youtube Video transcripts and generate a list of relevant chapters with their matching keyframes time (starttime and endtime), so the users can then jump to the section that are interesting to them.\n",
    "        \n",
    "        - Capture the key points of the content.\n",
    "        - Keep the summary brief and easy to understand.\n",
    "        - Avoid summarizing overly lengthy texts or breaking them into excessively short summaries.\n",
    "        - Use bullet points where appropriate to enhance clarity and structure.\n",
    "        - precise clearly their starttime and endtime in the video\n",
    "        \"\"\"        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompts },\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize the following text:\\n{text}\"}\n",
    "        ]\n",
    "        \n",
    "        response = ollama.chat(model=MODEL, messages=messages)\n",
    "        # print(response['message']['content'])\n",
    "        return response['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing text: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a62e5d56-149e-4436-bc2e-9a0e28c41b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=kqaMIFEz15s\"\n",
    "yt_video = YoutubeVideoID(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0637c1a8-8428-4f90-b369-3280abd77fda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16073\n"
     ]
    }
   ],
   "source": [
    "# Fetch transcript using the video ID\n",
    "transcript_text = get_transcript(yt_video.video_id)\n",
    "print(len(transcript_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6980185d-f35b-4070-9621-690e84095178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize text using ChatGPT\n",
    "def generate_chapters(summaries):\n",
    "    try:\n",
    "        system_prompts = \"\"\"\n",
    "        You take a list of summaries from a video with their associated startime and endtime, and find an accurate timeline for the video the the user can jump to different sections.\n",
    "        \n",
    "        - Find an accurate title for each section you come up with.\n",
    "        - Specify a starttime and and entime with bullet points.\n",
    "        - you do not need to have the same number of section as the summaries that are passed to you.\n",
    "        \"\"\"        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompts },\n",
    "            {\"role\": \"user\", \"content\": f\"Find the different sections from these summaries:\\n{summaries}\"}\n",
    "        ]\n",
    "        \n",
    "        response = ollama.chat(model=MODEL, messages=messages)\n",
    "        # print(response['message']['content'])\n",
    "        return response['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing text: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8bd2aec-b482-4acd-8455-3ba747d36b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a summary of each section:\n",
       "\n",
       "**Section 1: Reviewing Past Predictions**\n",
       "\n",
       "* Title: \"Reviewing Past Predictions\"\n",
       "* Starttime: 0:30\n",
       "* Endtime: 3:45\n",
       "* Keyframe Times:\n",
       "\t+ Chapter 1 review (0:30 - 1:15)\n",
       "\t+ Past predictions (1:15 - 2:00)\n",
       "\t+ Deep fakes (2:00 - 3:45)\n",
       "\n",
       "**Section 2: Implications of Generative AI on Cybersecurity**\n",
       "\n",
       "* Title: \"Implications of Generative AI on Cybersecurity\"\n",
       "* Starttime: 0:45\n",
       "* Endtime: 12:45\n",
       "* Keyframe Times:\n",
       "\t+ Prompt injection attacks (0:45 - 2:00)\n",
       "\t+ Lack of defenses (3:30 - 5:00)\n",
       "\t+ Cybersecurity using Generative AI (6:15 - 9:00)\n",
       "\n",
       "**Section 3: Quantum Computers and Cryptography**\n",
       "\n",
       "* Title: \"Quantum Computers and Cryptography\"\n",
       "* Starttime: 10:30\n",
       "* Endtime: 12:45\n",
       "* Keyframe Times:\n",
       "\t+ Quantum computers posing a threat to traditional cryptography (10:30 - 11:15)\n",
       "\t+ Researchers working on quantum-safe cryptographic methods (11:15 - 12:00)\n",
       "\n",
       "**Section 4: Action Required**\n",
       "\n",
       "* Title: \"Action Required\"\n",
       "* Starttime: 12:45\n",
       "* Endtime: 13:50\n",
       "* Keyframe Times:\n",
       "\t+ Organizations need to start working on quantum-safe cryptography (12:45 - 14:30)\n",
       "\t+ Developing projects to convert to new quantum-safe cryptography (14:30 - 15:20)\n",
       "\n",
       "**Section 5: Additional Resources**\n",
       "\n",
       "* Title: \"Additional Resources\"\n",
       "* Starttime: 16:00\n",
       "* Endtime: 17:10\n",
       "* Keyframe Times:\n",
       "\t+ Watching videos on the IBM Technology Channel for deeper dives into these topics (16:00 - 17:10)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transcript_chunks = split_text(transcript_text)\n",
    "\n",
    "# Now you can summarize each chunk individually\n",
    "summaries = []\n",
    "for chunk in transcript_chunks:  # Only the first element\n",
    "    summary = summarize_text(chunk)\n",
    "    summaries.append(summary)\n",
    "\n",
    "# Combine the individual summaries into one\n",
    "full_summary = \" \".join(summaries)\n",
    "display(Markdown(generate_chapters(full_summary)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
