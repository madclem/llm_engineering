{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f013456d-28c2-4f6b-bf02-9412891e27ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shiny\n",
      "  Downloading shiny-1.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.16.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (0.34.0)\n",
      "Requirement already satisfied: starlette in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (0.46.0)\n",
      "Requirement already satisfied: websockets>=13.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (15.0)\n",
      "Collecting htmltools>=0.6.0 (from shiny)\n",
      "  Downloading htmltools-0.6.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: click>=8.1.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (8.1.8)\n",
      "Requirement already satisfied: markdown-it-py>=1.1.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (3.0.0)\n",
      "Collecting mdit-py-plugins>=0.3.0 (from shiny)\n",
      "  Downloading mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting linkify-it-py>=1.0 (from shiny)\n",
      "  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting appdirs>=1.4.4 (from shiny)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: asgiref>=3.5.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (3.8.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (24.2)\n",
      "Requirement already satisfied: watchfiles>=0.18.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (1.0.4)\n",
      "Collecting questionary>=2.0.0 (from shiny)\n",
      "  Downloading questionary-2.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: prompt-toolkit in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (3.0.50)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (0.0.20)\n",
      "Requirement already satisfied: narwhals>=1.10.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (1.27.1)\n",
      "Requirement already satisfied: orjson>=3.10.7 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from shiny) (3.10.15)\n",
      "Collecting uc-micro-py (from linkify-it-py>=1.0->shiny)\n",
      "  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from markdown-it-py>=1.1.0->shiny) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from prompt-toolkit->shiny) (0.2.13)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from uvicorn>=0.16.0->shiny) (0.14.0)\n",
      "Requirement already satisfied: anyio>=3.0.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from watchfiles>=0.18.0->shiny) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anyio>=3.0.0->watchfiles>=0.18.0->shiny) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anyio>=3.0.0->watchfiles>=0.18.0->shiny) (1.3.1)\n",
      "Downloading shiny-1.3.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading htmltools-0.6.0-py3-none-any.whl (84 kB)\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
      "Downloading questionary-2.1.0-py3-none-any.whl (36 kB)\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: appdirs, uc-micro-py, htmltools, questionary, mdit-py-plugins, linkify-it-py, shiny\n",
      "Successfully installed appdirs-1.4.4 htmltools-0.6.0 linkify-it-py-2.0.3 mdit-py-plugins-0.4.2 questionary-2.1.0 shiny-1.3.0 uc-micro-py-1.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install shiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "from shiny import App, Inputs, Outputs, Session, render, ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5d8880-f2ee-4c06-af16-ecbc0262af61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "106dd65e-90af-4ca8-86b6-23a41840645b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have GPT-4o-mini figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-4o-mini to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97e4068-97ed-4120-beae-c42105e4d59a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
      "You should respond in JSON as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bcbfa78-6395-4685-b92c-22d592050fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://edwarddonner.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "https://edwarddonner.com/\n",
      "https://news.ycombinator.com\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://patents.google.com/patent/US20210049536A1/\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/2024/12/21/llm-resources-superdatascience/\n",
      "https://edwarddonner.com/2024/12/21/llm-resources-superdatascience/\n",
      "https://edwarddonner.com/2024/11/13/llm-engineering-resources/\n",
      "https://edwarddonner.com/2024/11/13/llm-engineering-resources/\n",
      "https://edwarddonner.com/2024/10/16/from-software-engineer-to-ai-data-scientist-resources/\n",
      "https://edwarddonner.com/2024/10/16/from-software-engineer-to-ai-data-scientist-resources/\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://www.facebook.com/edward.donner.52\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a29aca19-ca13-471c-a4b4-5abbfa813f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a827a0-2782-4ae5-b210-4a242a8b4cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Anthropic has made their site harder to scrape, so I'm using HuggingFace..\n",
    "\n",
    "huggingface = Website(\"https://huggingface.co\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://huggingface.co/about'},\n",
       "  {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'},\n",
       "  {'type': 'company page', 'url': 'https://huggingface.co/huggingface'},\n",
       "  {'type': 'blog page', 'url': 'https://huggingface.co/blog'},\n",
       "  {'type': 'community page', 'url': 'https://discuss.huggingface.co'},\n",
       "  {'type': 'LinkedIn page',\n",
       "   'url': 'https://www.linkedin.com/company/huggingface/'},\n",
       "  {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'},\n",
       "  {'type': 'GitHub page', 'url': 'https://github.com/huggingface'},\n",
       "  {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'},\n",
       "  {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT4-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(get_all_details(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/about'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'company blog', 'url': 'https://huggingface.co/blog'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title:\\nHugging Face – The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nQwen/QwQ-32B\\nUpdated\\nabout 5 hours ago\\n•\\n8.74k\\n•\\n996\\nmicrosoft/Phi-4-multimodal-instruct\\nUpdated\\n1 day ago\\n•\\n71.2k\\n•\\n913\\ndeepseek-ai/DeepSeek-R1\\nUpdated\\n10 days ago\\n•\\n4.25M\\n•\\n10.9k\\nWan-AI/Wan2.1-T2V-14B\\nUpdated\\n8 days ago\\n•\\n170k\\n•\\n872\\nallenai/olmOCR-7B-0225-preview\\nUpdated\\n10 days ago\\n•\\n109k\\n•\\n439\\nBrowse 1M+ models\\nSpaces\\nRunning\\n905\\n905\\nWan2.1\\n💻\\nWan: Open and Advanced Large-Scale Video Generative Models\\nRunning\\n2.08k\\n2.08k\\nThe Ultra-Scale Playbook\\n🌌\\nThe ultimate guide to training LLM on large GPU Clusters\\nRunning\\non\\nZero\\n219\\n219\\nDi♪♪Rhythm\\n🎶\\nBlazingly Fast and Embarrassingly Simple Song Generation\\nRunning\\non\\nZero\\n7.67k\\n7.67k\\nFLUX.1 [dev]\\n🖥\\nGenerate images from text prompts\\nRunning\\n158\\n158\\nQwQ 32B Demo\\n🌖\\nGenerate text responses based on user input\\nBrowse 400k+ applications\\nDatasets\\nfacebook/natural_reasoning\\nUpdated\\n13 days ago\\n•\\n7.28k\\n•\\n321\\nCongliu/Chinese-DeepSeek-R1-Distill-data-110k\\nUpdated\\n14 days ago\\n•\\n6.17k\\n•\\n475\\nFreedomIntelligence/medical-o1-reasoning-SFT\\nUpdated\\n12 days ago\\n•\\n26k\\n•\\n366\\nSynthLabsAI/Big-Math-RL-Verified\\nUpdated\\n8 days ago\\n•\\n3.7k\\n•\\n126\\nGeneralReasoning/GeneralThought-195K\\nUpdated\\n3 days ago\\n•\\n284\\n•\\n47\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nEnterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n•\\n391 models\\n•\\n2.69k followers\\nAI at Meta\\nEnterprise\\ncompany\\n•\\n2.07k models\\n•\\n4.94k followers\\nAmazon\\ncompany\\n•\\n20 models\\n•\\n2.81k followers\\nGoogle\\ncompany\\n•\\n959 models\\n•\\n8.54k followers\\nIntel\\ncompany\\n•\\n219 models\\n•\\n2.31k followers\\nMicrosoft\\ncompany\\n•\\n362 models\\n•\\n9.91k followers\\nGrammarly\\nEnterprise\\ncompany\\n•\\n10 models\\n•\\n131 followers\\nWriter\\nEnterprise\\ncompany\\n•\\n20 models\\n•\\n246 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n140,742\\nState-of-the-art ML for PyTorch, TensorFlow, JAX\\nDiffusers\\n27,862\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,148\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,396\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,445\\nFast tokenizers optimized for research & production\\nTRL\\n12,256\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n13,124\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n13,769\\nSmol library to build great agents in Python\\nPEFT\\n17,642\\nParameter-efficient finetuning for large language models\\nDatasets\\n19,739\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n9,855\\nServe language models with TGI optimized toolkit\\nAccelerate\\n8,434\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nTasks\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nabout page\\nWebpage Title:\\nabout (Sergei)\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nSergei\\nabout\\nFollow\\nAlbertRuan's profile picture\\nRenumathi's profile picture\\nselvivincent's profile picture\\n4\\n\\t\\t\\t\\t\\tfollowers\\n·\\n0 following\\nAI & ML interests\\nNone yet\\nOrganizations\\nNone yet\\nmodels\\nNone public yet\\ndatasets\\nNone public yet\\nSystem theme\\nCompany\\nTOS\\nPrivacy\\nAbout\\nJobs\\nWebsite\\nModels\\nDatasets\\nSpaces\\nPricing\\nDocs\\n\\n\\n\\ncareers page\\nWebpage Title:\\nHugging Face - Current Openings\\nWebpage Contents:\\n\\n\\n\\n\\ncompany blog\\nWebpage Title:\\nHugging Face – Blog\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nBlog, Articles, and discussions\\nNew Article\\nEverything\\ncommunity\\nguid\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e44de579-4a1a-4e6a-a510-20ea3e4b8d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e093444a-9407-42ae-924a-145730591a39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'community page', 'url': 'https://discuss.huggingface.co'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Hugging Face - The AI Community Building the Future\n",
       "\n",
       "Welcome to Hugging Face, where the machine learning community collaborates to create the future of AI. Our platform serves as a nexus for developers, researchers, and companies to build, deploy, and share cutting-edge machine learning models, datasets, and applications.\n",
       "\n",
       "---\n",
       "\n",
       "## About Us\n",
       "Hugging Face is revolutionizing the AI landscape by fostering collaboration and innovation within the machine learning community. We provide tools and open-source libraries that empower users to create unified workflows for model development across various modalities, including text, image, video, audio, and 3D.\n",
       "\n",
       "---\n",
       "\n",
       "## Our Offerings\n",
       "- **Models**: Access over 1 million models across various tasks, including language processing and image recognition. Our trending models this week include notable entries from leaders like Microsoft and AllenAI.\n",
       "- **Datasets**: Explore more than 250,000 datasets curated for a variety of machine learning tasks, ensuring easy access to the data you need.\n",
       "- **Spaces**: Collaborate on public applications to showcase your work, from AI-generated images to music composition.\n",
       "\n",
       "---\n",
       "\n",
       "## Our Community\n",
       "Join a community of over 50,000 organizations, including:\n",
       "- **Amazon**\n",
       "- **Google**\n",
       "- **Microsoft**\n",
       "- **Meta**\n",
       "\n",
       "Collaborate and follow peers while sharing your projects and insights.\n",
       "\n",
       "---\n",
       "\n",
       "## Company Culture\n",
       "At Hugging Face, we believe in a collaborative, open-source culture that prioritizes inclusivity and shared growth. Our dedicated team, composed of machine learning enthusiasts and professionals, contributes to a nurturing environment where ideas can flourish and individuals can learn from each other. We seek to empower our members to explore, innovate, and impact the machine learning landscape positively.\n",
       "\n",
       "---\n",
       "\n",
       "## Careers at Hugging Face\n",
       "We are looking for passionate individuals to join our growing team. If you're interested in shaping the future of AI, check our careers page for opportunities where you can develop your skills and advance your career. We're committed to maintaining an inclusive work environment that embraces diversity and encourages personal and professional growth.\n",
       "\n",
       "**Positions Available:**  \n",
       "- Machine Learning Engineers  \n",
       "- Software Developers  \n",
       "- Community Managers  \n",
       "- Data Scientists  \n",
       "\n",
       "*Explore more opportunities on our [Jobs page](https://huggingface.co/jobs)*\n",
       "\n",
       "---\n",
       "\n",
       "## Get Involved\n",
       "Join us as we build the future of AI! Sign up for free on our platform today and start collaborating with a global network of machine learning practitioners. \n",
       "\n",
       "[Sign Up Now](https://huggingface.co/signup) \n",
       "\n",
       "---\n",
       "\n",
       "## Connect With Us\n",
       "Stay up to date with our latest updates and community discussions. Join us on social media:\n",
       "- [GitHub](https://github.com/huggingface)\n",
       "- [Twitter](https://twitter.com/huggingface)\n",
       "- [LinkedIn](https://www.linkedin.com/company/huggingface)\n",
       "- [Discord](https://discord.gg/huggingface)\n",
       "\n",
       "Let’s build something amazing together! \n",
       "\n",
       "---\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brochure_en = stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cb757d6-9d47-459c-a3a7-fb4c1bedf972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_brochure_translation_user_prompt(language, brochure):\n",
    "    user_prompt = f\"You are receiving a brochure that you need to translate in{language}. Keep the markdown format.\\n\"\n",
    "    user_prompt += \"here is the brochure's content\"\n",
    "    user_prompt += brochure\n",
    "    return user_prompt\n",
    "\n",
    "def translate_brochure(lang, brochure):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"you're a bot that takes an input text in english and translates it to a specific language. Write it in markdown.\" },\n",
    "            {\"role\": \"user\", \"content\": get_brochure_translation_user_prompt(lang, brochure)}\n",
    "          ]\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'company page', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'blog', 'url': 'https://huggingface.co/blog'}, {'type': 'community discussion', 'url': 'https://discuss.huggingface.co'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Hugging Face Brochure\n",
       "\n",
       "## Company Overview\n",
       "**Hugging Face** is the leading community and platform dedicated to advancing artificial intelligence (AI) and machine learning (ML) through collaboration and innovation. Our mission is to democratize AI, making it accessible to everyone while fostering a robust and engaged community that builds the future of technology together.\n",
       "\n",
       "### What We Offer\n",
       "- **Models**: Access a vast library with over 1 million models, including state-of-the-art solutions for various applications.\n",
       "- **Datasets**: Browse through 250,000+ datasets for your machine learning projects.\n",
       "- **Spaces**: Collaborate on applications and run innovative projects in a supportive environment.\n",
       "\n",
       "## Our Community\n",
       "At Hugging Face, community is at the heart of everything we do. We engage with:\n",
       "- **Over 50,000 Organizations**: From tech giants like Google, Microsoft, and Amazon to passionate NGOs, all leveraging our technology to enhance their AI capabilities.\n",
       "- **Contributors and Innovators**: Collaborators globally work on creating and improving models and datasets, sharing their insights and advancements.\n",
       "\n",
       "## Company Culture\n",
       "We believe in **open collaboration** and **creativity**. Our company culture is defined by:\n",
       "- **Innovation**: Encouraging team members to push boundaries and explore new ideas.\n",
       "- **Inclusivity**: Welcoming diverse perspectives and experiences to foster a rich and vibrant community.\n",
       "- **Support**: Providing dedicated support and resources to make every member's journey in AI fruitful and rewarding.\n",
       "\n",
       "## Career Opportunities\n",
       "Join our mission to make AI better for everyone! At Hugging Face, we are always looking for:\n",
       "- Developers\n",
       "- Data Scientists\n",
       "- Community Managers\n",
       "- AI Researchers\n",
       "\n",
       "### Why Work With Us?\n",
       "- **Impact**: Be part of a company that is shaping the future of AI and ML.\n",
       "- **Growth**: Opportunities for personal and professional growth through community engagement and open-source projects.\n",
       "- **Benefits**: Competitive salaries, comprehensive health benefits, and a supportive work environment.\n",
       "\n",
       "## Get Involved\n",
       "Interested in contributing or learning more about what we do? Join us in our mission to build a better AI future.  \n",
       "**Visit us at [Hugging Face](https://huggingface.co)**  \n",
       "**Follow us on [Twitter](https://twitter.com/huggingface) and [LinkedIn](https://www.linkedin.com/company/huggingface)**\n",
       "\n",
       "### Together, Let's Build the Future of AI!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "brochure = stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b2271e4-d38f-4287-8470-a28db33e8c04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipywidgets) (9.0.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ace46ab6-7763-4508-9585-7c831ca8da3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226502d2401f44bd962d3fb5b38ea1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Language:', index=3, options=('Portuguese', 'French', 'Esperanto', 'English'), style=Des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define the list of languages\n",
    "languages = [\"Portuguese\", \"French\", \"Esperanto\", \"English\"]\n",
    "\n",
    "# Create a dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=languages,\n",
    "    value=\"English\",  # Default selection\n",
    "    description=\"Language:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Display the dropdown\n",
    "display(dropdown)\n",
    "\n",
    "# Function to capture selection\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        translate_brochure(change['new'], brochure)\n",
    "        # print(f\"Selected language: {change['new']}\")\n",
    "\n",
    "# Attach event listener\n",
    "dropdown.observe(on_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3e1a1-ba54-4907-97c5-30f89a24775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
